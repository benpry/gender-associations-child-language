{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b2ccf4-b9ff-4945-b115-a0281553df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f9323d-8678-4189-a4c8-2018a72383f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FREQ = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f30d05-6b04-4b4d-8f3a-2a8c088dc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute words for association testing\n",
    "f_words_proj = ['she', 'her', 'woman', 'Mary', 'herself', 'daughter', 'mother', 'gal', 'girl', 'female']\n",
    "m_words_proj = ['he', 'his', 'man', 'John', 'himself', 'son', 'father', 'guy', 'boy', 'male']\n",
    "m_words_weat = ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
    "f_words_weat = ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
    "\n",
    "# a list of all explicitly gendered words, manually selected\n",
    "gendered_words = [\"miss\", \"mister\", \"blonde\", \"blond\", \"he\", \"she\", \"prince\", \"princess\", \"moms\", \"dads\", \"mama\",\n",
    "                  \"dada\", \"papa\", \"auntie\", \"aunt\", \"uncle\", \"mothers\", \"fathers\", \"momma\", \"mother\", \"father\",\n",
    "                  \"gramma\", \"grampa\", \"grandmother\", \"grandfather\", \"girls\", \"boys\", \"brother\", \"sister\", \"mommies\",\n",
    "                  \"daddies\", \"woman\", \"man\", \"policeman\", \"policewoman\", \"mummie\", \"daddie\", \"lady\", \"gentleman\",\n",
    "                  \"lord\", \"guy\", \"gal\", \"daughter\", \"son\", \"missus\", \"women\", \"men\", \"cowboy\", \"cowgirl\", \"stepsisters\",\n",
    "                  \"stepmother\", \"stepfather\", \"stepbrothers\", \"grandma\", \"grandpa\", \"grandfather\", \"grandmother\", \"ladies\",\n",
    "                  \"gentlemen\", \"himself\", \"herself\", \"boyfriend\", \"girlfriend\", \"female\", \"male\", \"girl\", \"boy\", \"godmother\", \n",
    "                  \"godfather\", \"husband\", \"wife\", \"fireman\", \"firewoman\", \"mum\", \"pop\", \"his\", \"her\", \"hers\", \"stewardess\",\n",
    "                  \"steward\", \"daughters\", \"sons\", \"mommy\", \"daddy\"]\n",
    "\n",
    "words_to_exclude = set(f_words_proj + m_words_proj + m_words_weat + f_words_weat + gendered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2acd1d40-aebe-4575-badf-71a979a2acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cds = pd.read_csv(\"../../data/whole_corpus/df_cds_agg.csv\")\n",
    "df_cs = pd.read_csv(\"../../data/whole_corpus/df_cs_agg.csv\")\n",
    "df_cds = df_cds[df_cds[\"freq\"] >= MIN_FREQ]\n",
    "df_cs = df_cs[df_cs[\"freq\"] >= MIN_FREQ]\n",
    "df_cds = df_cds[df_cds[\"word\"].apply(lambda x: x.isalpha() and x == x.lower() and x not in words_to_exclude)]\n",
    "df_cs = df_cs[df_cs[\"word\"].apply(lambda x: x.isalpha() and x == x.lower() and x not in words_to_exclude)]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48fa9196-59c0-42db-b003-447ae3b2597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_to_latex(df):\n",
    "    for index, row in df.iterrows():\n",
    "        print(f\"{row['word']} & {str(np.round(row['pfgw'], 2)).ljust(4, '0')} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0601078d-c5e1-44fb-a95a-c51dd40bfcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30_cds = df_cds.sort_values(by=\"pfgw\").tail(30).iloc[::-1]\n",
    "bottom_30_cds = df_cds.sort_values(by=\"pfgw\").head(30)\n",
    "df_cds[\"mid_distance\"] = df_cds[\"pfgw\"].apply(lambda x: abs(0.5 - x))\n",
    "mid_30_cds = df_cds.sort_values(by=\"mid_distance\").head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7ed3252-e981-4e9c-8035-ec82362c2b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creamcheese & 1.00 \\\\\n",
      "giddy & 1.00 \\\\\n",
      "nom & 1.00 \\\\\n",
      "ponies & 1.00 \\\\\n",
      "dale & 1.00 \\\\\n",
      "tapioca & 1.00 \\\\\n",
      "oompapa & 1.00 \\\\\n",
      "pigtails & 1.00 \\\\\n",
      "tinkertoy & 1.00 \\\\\n",
      "tutu & 1.00 \\\\\n",
      "puttaputta & 1.00 \\\\\n",
      "dice & 1.00 \\\\\n",
      "sleeper & 1.00 \\\\\n",
      "yall & 0.99 \\\\\n",
      "courage & 0.97 \\\\\n",
      "mane & 0.96 \\\\\n",
      "dolly & 0.94 \\\\\n",
      "marry & 0.94 \\\\\n",
      "marmalade & 0.94 \\\\\n",
      "valentine & 0.93 \\\\\n",
      "mash & 0.93 \\\\\n",
      "stool & 0.92 \\\\\n",
      "cottage & 0.92 \\\\\n",
      "mam & 0.92 \\\\\n",
      "untill & 0.91 \\\\\n",
      "kittys & 0.91 \\\\\n",
      "ponytail & 0.91 \\\\\n",
      "cricket & 0.91 \\\\\n",
      "fishie & 0.90 \\\\\n",
      "ribbon & 0.90 \\\\\n"
     ]
    }
   ],
   "source": [
    "rows_to_latex(top_30_cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e51ff7ad-65bb-4374-ab3e-f702c1cb402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee & 0.00 \\\\\n",
      "violent & 0.00 \\\\\n",
      "moomilk & 0.00 \\\\\n",
      "pirate & 0.00 \\\\\n",
      "choochoo & 0.00 \\\\\n",
      "shishi & 0.00 \\\\\n",
      "clop & 0.00 \\\\\n",
      "pau & 0.00 \\\\\n",
      "spear & 0.00 \\\\\n",
      "cemetery & 0.00 \\\\\n",
      "budleyley & 0.00 \\\\\n",
      "chugga & 0.00 \\\\\n",
      "swingie & 0.00 \\\\\n",
      "ooaa & 0.00 \\\\\n",
      "scales & 0.00 \\\\\n",
      "budleyleys & 0.00 \\\\\n",
      "underoos & 0.00 \\\\\n",
      "ninight & 0.00 \\\\\n",
      "twerp & 0.00 \\\\\n",
      "badada & 0.00 \\\\\n",
      "didldow & 0.00 \\\\\n",
      "squirrelie & 0.00 \\\\\n",
      "bomber & 0.00 \\\\\n",
      "nuuw & 0.00 \\\\\n",
      "mwuh & 0.00 \\\\\n",
      "shore & 0.00 \\\\\n",
      "badji & 0.00 \\\\\n",
      "infinity & 0.00 \\\\\n",
      "nem & 0.00 \\\\\n",
      "eeat & 0.00 \\\\\n"
     ]
    }
   ],
   "source": [
    "rows_to_latex(bottom_30_cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2199129-116b-4779-ba32-66e1e329ed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unless & 0.50 \\\\\n",
      "will & 0.50 \\\\\n",
      "on & 0.50 \\\\\n",
      "show & 0.50 \\\\\n",
      "potato & 0.50 \\\\\n",
      "writing & 0.50 \\\\\n",
      "able & 0.50 \\\\\n",
      "hamburger & 0.50 \\\\\n",
      "me & 0.50 \\\\\n",
      "eaten & 0.50 \\\\\n",
      "please & 0.50 \\\\\n",
      "mailman & 0.50 \\\\\n",
      "first & 0.50 \\\\\n",
      "there & 0.50 \\\\\n",
      "nothing & 0.50 \\\\\n",
      "in & 0.50 \\\\\n",
      "pages & 0.50 \\\\\n",
      "no & 0.50 \\\\\n",
      "yes & 0.50 \\\\\n",
      "anything & 0.50 \\\\\n",
      "phone & 0.50 \\\\\n",
      "tastes & 0.50 \\\\\n",
      "than & 0.50 \\\\\n",
      "mud & 0.50 \\\\\n",
      "know & 0.50 \\\\\n",
      "froggie & 0.50 \\\\\n",
      "everything & 0.50 \\\\\n",
      "all & 0.50 \\\\\n",
      "awhile & 0.50 \\\\\n",
      "yours & 0.50 \\\\\n"
     ]
    }
   ],
   "source": [
    "rows_to_latex(mid_30_cds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
